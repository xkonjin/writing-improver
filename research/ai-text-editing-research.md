# Professional Editing of AI Text — Research Summary

## Core Principle

"Editing is subtractive first, additive second." Remove AI markers before adding human elements. This maps to our Phase 4 (structural scan) → Phase 5 (vocabulary scan) → Phase 6 (revision/addition).

## Multi-Pass Editing Hierarchy

1. **Structural/Logical** — Re-organize argument, break thesis-evidence-conclusion, add asymmetry
2. **Sentence/Syntactic** — Fix uniform sentence patterns, vary length, increase burstiness
3. **Vocabulary/Word** — Eliminate AI clichés, replace formal transitions

Layered edits compound effectiveness — each pass on a different dimension creates more effective humanization than single-pass editing.

## What Professional Editors Fix First

- Opening sentence ("inevitably terrible by any editor's standards")
- Uniform paragraph lengths → create asymmetry (1-2 sentence paragraphs alongside 6-7 sentence ones)
- Signposting phrases ("In this section," "As mentioned," "It's worth noting")
- AI vocabulary markers (delve, robust, pivotal, realm, intricate)
- Lists → flowing prose (LLMs overuse bullets because of training data)
- Thesis-evidence-conclusion structure → narrative/exploratory structure

## Controlled Messiness

"AI models are built for logic and coherence, which leads to writing that feels 'a little too perfect.' The biggest red flags are the subtle absence of the beautiful messiness that defines human expression."

Strategic imperfections that signal humanity:

- Sentence fragments for emphasis
- Starting with "And" or "But"
- Mixing formal and casual tone
- Varying terminology (don't be perfectly consistent)
- Minor redundancy (circling back to reinforce)
- Trailing thoughts...

The paradox: less polished text sounds more authentic — but only to a point. The art is **controlled messiness**, not actual sloppiness.

## Detection Research (2025-2026)

- Paraphrasing + humanization reduced AI detection from 91% to 4%
- Human-written articles generate 5.44x more traffic and hold attention 41% longer
- Suspected AI content reduces reader trust by ~50%
- Blinded human reviewers correctly classify text source < 70% of the time
- "AI slop" was 2025 Word of the Year (Merriam-Webster)

## The Uncanny Valley for Text

Text that is "almost, but not quite" human provokes more unease than obviously AI text. Strong reader preference for naturalness, human imperfections, and vulnerability. Deviations that disrupt perceived humanity trigger the uncanny valley — so partial humanization can be worse than none.

## Key Insight for Our System

Our system already covers this well. The main validation from this research:

1. Structure matters more than vocabulary (confirmed)
2. Multi-pass approach works best (confirmed — our Phases 4-6)
3. Opening sentence should always be rewritten (already in our guidelines)
4. Subtractive first, additive second (already our Phase ordering)
5. Controlled messiness is strategic, not random (worth remembering)

## Sources

- EditLens (2025): Quantifying extent of AI editing in text
- MIT Uncanny Valley study (2025): Human perceptions of AI text
- "From Pen to Prompt" (2025): 18 creative writers integrating AI
- FSU research: Why ChatGPT "delves" so much
- Grafit Agency: AI vs human content performance (5.44x traffic)
